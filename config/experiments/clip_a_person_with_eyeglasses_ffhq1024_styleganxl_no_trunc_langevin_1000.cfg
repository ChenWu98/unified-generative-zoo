[model]
name = langevin_dynamics
step_size = 0.05
n_steps = 200

[gan]
gan_type = StyleGAN-XL
network_pkl = https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/ffhq1024.pkl
sample_truncation = 1

[raw_data]
upsample_temp = 1

[arg_paths]
ffhq_clip = tasks/clip_coverage.cfg

[CLIPEnergy]
weight = 1000
text = a photo of a person with eyeglasses
clip_models = ["ViT-B/32"]
clip_model_weights = [1.0]

[PriorZEnergy]
weight = 1

[evaluation]
evaluator_program = multi_task

[visualization]
visualizer_program = single_image