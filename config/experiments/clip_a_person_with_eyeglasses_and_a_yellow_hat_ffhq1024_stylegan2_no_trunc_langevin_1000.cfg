[model]
name = langevin_dynamics
step_size = 0.05
n_steps = 200

[gan]
gan_type = StyleGAN2
source_model_type = ffhq
sample_truncation = 1
randomize_noise = true

[raw_data]
upsample_temp = 1

[arg_paths]
ffhq_clip = tasks/clip_coverage.cfg

[CLIPEnergy]
weight = 1000
text = a photo of a person with eyeglasses and a yellow hat
clip_models = ["ViT-B/32"]
clip_model_weights = [1.0]

[PriorZEnergy]
weight = 1

[evaluation]
evaluator_program = multi_task

[visualization]
visualizer_program = single_image