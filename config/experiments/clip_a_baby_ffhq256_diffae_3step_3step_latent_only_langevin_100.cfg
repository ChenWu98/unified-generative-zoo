[model]
name = langevin_dynamics
step_size = 0.05
n_steps = 200

[gan]
gan_type = DiffAE
source_model_type = ffhq256
latent_only = True
latent_steps_train = 3
steps_train = 3

[raw_data]
upsample_temp = 1

[arg_paths]
ffhq_clip = tasks/clip_coverage.cfg

[CLIPEnergy]
weight = 100
text = a photo of a baby
clip_models = ["ViT-B/32"]
clip_model_weights = [1.0]

[PriorZEnergy]
weight = 1

[evaluation]
evaluator_program = multi_task

[visualization]
visualizer_program = single_image